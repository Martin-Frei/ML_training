{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abrufe Daten für AAL von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für AAL gefunden.\n",
      "Abrufe Daten für AAPL von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für AAPL gefunden.\n",
      "Abrufe Daten für ANET von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['ANET']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für ANET gefunden.\n",
      "Abrufe Daten für BA von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BA']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für BA gefunden.\n",
      "Abrufe Daten für BYND von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BYND']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für BYND gefunden.\n",
      "Abrufe Daten für DAL von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['DAL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für DAL gefunden.\n",
      "Abrufe Daten für DELL von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['DELL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für DELL gefunden.\n",
      "Abrufe Daten für FTNT von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['FTNT']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für FTNT gefunden.\n",
      "Abrufe Daten für IBM von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['IBM']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für IBM gefunden.\n",
      "Abrufe Daten für LUV von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['LUV']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für LUV gefunden.\n",
      "Abrufe Daten für NFLX von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['NFLX']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für NFLX gefunden.\n",
      "Abrufe Daten für NVDA von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['NVDA']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für NVDA gefunden.\n",
      "Abrufe Daten für OXY von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['OXY']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für OXY gefunden.\n",
      "Abrufe Daten für PDD von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['PDD']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für PDD gefunden.\n",
      "Abrufe Daten für PYPL von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['PYPL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für PYPL gefunden.\n",
      "Abrufe Daten für RIO von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['RIO']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für RIO gefunden.\n",
      "Abrufe Daten für SPCE von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['SPCE']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für SPCE gefunden.\n",
      "Abrufe Daten für TSLA von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['TSLA']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für TSLA gefunden.\n",
      "Abrufe Daten für UAL von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['UAL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für UAL gefunden.\n",
      "Abrufe Daten für MSFT von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für MSFT gefunden.\n",
      "Abrufe Daten für GOOGL von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für GOOGL gefunden.\n",
      "Abrufe Daten für META von 2023-03-01 bis 2024-12-31 mit Intervall 1h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['META']: JSONDecodeError('Expecting value: line 1 column 1 (char 0)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Keine Daten für META gefunden.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "import pytz\n",
    "\n",
    "# New York Zeitzone\n",
    "NY_TZ = pytz.timezone(\"America/New_York\")\n",
    "\n",
    "def calculate_indicators(data):\n",
    "    \"\"\"Berechnet technische Indikatoren für die Aktienkursdaten.\"\"\"\n",
    "\n",
    "    # RSI-Berechnung\n",
    "    delta = data['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(window=14).mean()\n",
    "    loss = -delta.where(delta < 0, 0).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    data['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # EMA\n",
    "    data['EMA9'] = data['Close'].ewm(span=9, adjust=False).mean()\n",
    "    data['EMA21'] = data['Close'].ewm(span=21, adjust=False).mean()\n",
    "\n",
    "    # Bollinger Bänder\n",
    "    sma20 = data['Close'].rolling(window=20).mean()\n",
    "    rolling_std = data['Close'].rolling(window=20).std()\n",
    "    data['Upper Band'] = sma20 + (2 * rolling_std)\n",
    "    data['Lower Band'] = sma20 - (2 * rolling_std)\n",
    "\n",
    "    # ATR\n",
    "    data['High-Low'] = data['High'] - data['Low']\n",
    "    data['High-PrevClose'] = abs(data['High'] - data['Close'].shift(1))\n",
    "    data['Low-PrevClose'] = abs(data['Low'] - data['Close'].shift(1))\n",
    "    data['TR'] = data[['High-Low', 'High-PrevClose', 'Low-PrevClose']].max(axis=1)\n",
    "    data['ATR'] = data['TR'].rolling(window=14).mean()\n",
    "\n",
    "    # # Sicherstellen, dass alle Werte numerisch sind\n",
    "    # cols_to_fix = ['High', 'Low', 'Close', 'Volume']\n",
    "    # for col in cols_to_fix:\n",
    "    #     data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "    # # Fehlende Werte durch 0 ersetzen\n",
    "    # data.fillna({'High': 0, 'Low': 0, 'Close': 0, 'Volume': 0}, inplace=True)\n",
    "\n",
    "    # # **VWAP Berechnung**\n",
    "    # data['Typical_Price'] = (data['High'] + data['Low'] + data['Close']) / 3\n",
    "    # data['Typical_Price'] = data['Typical_Price'].fillna(0)\n",
    "    # data['Volume'] = data['Volume'].fillna(0)\n",
    "\n",
    "    # data['Cum_TPxV'] = (data['Typical_Price'] * data['Volume']).cumsum()\n",
    "    # data['Cum_Volume'] = data['Volume'].cumsum()\n",
    "\n",
    "    # # Schutz gegen Division durch Null\n",
    "    # data['VWAP'] = data['Cum_TPxV'] / data['Cum_Volume']\n",
    "    # data.loc[data['Cum_Volume'] == 0, 'VWAP'] = None \n",
    "\n",
    "    # #  Debug-Ausgabe für VWAP\n",
    "    # print(\" VWAP Debug-Daten:\")\n",
    "    # print(data[['Typical_Price', 'Volume', 'Cum_TPxV', 'Cum_Volume', 'VWAP']].head(20))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Stochastic Oscillator\n",
    "    low_min = data['Low'].rolling(window=14).min()\n",
    "    high_max = data['High'].rolling(window=14).max()\n",
    "    data['Stochastic'] = 100 * ((data['Close'] - low_min) / (high_max - low_min))\n",
    "\n",
    "    # MACD\n",
    "    short_ema = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "    long_ema = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "    data['MACD'] = short_ema - long_ema\n",
    "    data['Signal Line'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # Prozentuale Änderung\n",
    "    data['Pct_Change'] = data['Close'].pct_change()\n",
    "    \n",
    "    data.head(10)\n",
    "\n",
    "    return data\n",
    "\n",
    "def fetch_and_save_stock_data(ticker, start_date, end_date, interval, save_path):\n",
    "    \"\"\"\n",
    "    Lädt Aktienkursdaten und speichert sie als CSV.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): Aktien-Ticker (z.B. 'AAPL').\n",
    "        start_date (str): Startdatum ('YYYY-MM-DD').\n",
    "        end_date (str): Enddatum ('YYYY-MM-DD').\n",
    "        interval (str): Intervall ('1h', '1d', etc.).\n",
    "        save_path (str): Speicherpfad.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Abrufe Daten für {ticker} von {start_date} bis {end_date} mit Intervall {interval}...\")\n",
    "\n",
    "        # 📌 Daten abrufen\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, interval=interval)\n",
    "\n",
    "        if data.empty:\n",
    "            print(f\"❌ Keine Daten für {ticker} gefunden.\")\n",
    "            return\n",
    "\n",
    "        # 📌 Index zurücksetzen (damit \"Date\" als Spalte erscheint)\n",
    "        data.reset_index(inplace=True)\n",
    "\n",
    "        # 📌 Zeitzone auf New York setzen\n",
    "        data['Datetime'] = data['Datetime'].dt.tz_convert(NY_TZ).dt.tz_localize(None)\n",
    "\n",
    "        # 📌 Indikatoren berechnen\n",
    "        data = calculate_indicators(data)\n",
    "\n",
    "        # 📌 Speichern als CSV\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        file_name = f\"{ticker}.csv\"\n",
    "        file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "        # Datei überschreiben (keine Erweiterung)\n",
    "        data.to_csv(file_path, index=False)\n",
    "        print(f\"✅ Datei gespeichert: {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Fehler für {ticker}: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Aktienliste & Parameter\n",
    "    stocks = ['AAL','AAPL','ANET','BA', 'BYND','DAL','DELL', 'FTNT','IBM','LUV', 'NFLX','NVDA','OXY','PDD','PYPL','RIO','SPCE','TSLA','UAL','MSFT', 'GOOGL', 'META']\n",
    "    start_date = '2023-03-01'\n",
    "    end_date = '2024-12-31'\n",
    "    interval = '1h'\n",
    "    save_path = \"C:/Users/Martin/Documents/StockData\"\n",
    "\n",
    "    # Daten abrufen & speichern\n",
    "    for stock in stocks:\n",
    "        fetch_and_save_stock_data(stock, start_date, end_date, interval, save_path)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
